<!-- <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"> -->
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width initial-scale=1" />
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<div style="width:80%; margin:0 auto;">


<title>KDD'21 Tutorial</title>
</head>
<body>

<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<!-- <div class="menu-category"><img class="menu" src="chuxu.jpg" width="110px" height="160px"  align="center"></div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publication</a></div>
<div class="menu-item"><a href="services.html">Service</a></div> -->
</td>

<center>
<h1>KDD2021 Tutorial: Data Efficient Learning on Graphs</h1>
</center>
<center>
<!-- <h2>PST Time: 1-5PM, Sunday, August 23rd, 2021</h2> -->
</center>

 <hr>

<h2 id="description">Description</h2>
Prevailing methods of graph representation learning (GRL) usually rely on learning from “big” data, requiring a large amount of labeled data for model training. However, it is common that graphs are associated with “small” labeled data as data annotation and labeling is always a time and resource consuming task. The fact overshadows GRL’s capability and applicability for many real situations. Therefore, data efficient learning on graphs has become essential for many real-world applications and there have been many studies working on this topic in recent years. In this tutorial, we will systematically review recent studies of data efficient learning on graphs, in particular a series of methods and applications of graph few-shot learning and graph self-supervised learning. At first, we will introduce the overview of graph representation learning methods, conventional few-shot learning and self-supervised learning techniques. Then, we will present the work of data efficient learning on graphs in terms of three major graph mining tasks at different granularity levels: node-level learning tasks, graph-level learning tasks, and edge-level learning tasks. In the end, we will conclude the tutorial and raise open problems and pressing issues in future research. The authors of this tutorial are active and productive researchers in this research area.
<br>
<font size="3" color="black" ><b>Keywords</b></font>: Graph Representation Learning, Data-Efficient Learning, Few-Shot Learning, Self-Supervised Learning<br>

<!-- <b>Proposal</b></font>: <a style="color: rgb(0, 43, 91); text-decoration: none;" href="KDD20_Tutorial.pdf">Multi-modal Network Representation Learning<font color="red"></font> </a>
 -->
 <hr>

<h2 id="content">Content</h2>
<h3>Part 1: Background and Overview </a>
</h3>

<h3>Part 2: Node-level Data Efficient Learning </h3>

<h3>Part 3: Graph-level Data Efficient Learning</h3> 

<h3>Part 4: Edge-level Data Efficient Learning</h3>

<h3>Part 5: Conclusions and Discussions</h3>

<hr>

<h2 id="presenter">Presenters</h2>
<!-- <h2><p><img src="ChuxuZhang.jpeg" alt="Smiley face" align="left" height="120" width="100"></p> &nbsp;</h2> -->
<a style="color: rgb(0, 43, 91); text-decoration: none;" href="https://chuxuzhang.github.io/"><font size="4"><b>
	<p><img src="image/CXZ.jpeg" alt="Smiley face" align="left" height="90" width="80"></p> &nbsp;Chuxu Zhang </b></font></a></div> is an Assistant Professor in the Department of Computer Science at the Brandeis University. His research interests are machine learning and data mining, especially for their applications in graph mining, recommender systems, and interdisciplinary topics (e.g., computational chemistry or healthcare). His work have appeared in KDD, WWW, AAAI, IJCAI, and so on.
<p></p>	

<a style="color: rgb(0, 43, 91); text-decoration: none;" href="http://www.ece.virginia.edu/~jl6qk/"><font size="4"><b><p><img src="image/JundongLi.jpeg" alt="Smiley face" align="left" height="90" width="80"></p> &nbsp;Jundong Li </b></font></a></div>  is an Assistant Professor in the Department of Electrical and Computer Engineering at the University of Virginia. His research interests are in data mining and machine learning, with a particular focus on graph mining and causality learning. His work on feature selection and graph representation learning are among the most cited articles in ACM CSUR, WSDM, SDM, and CIKM within the past five years according to Google Scholar Metrics. His was selected for the AAAI 2021 New Faculty Highlights program.
<p></p>	

<a style="color: rgb(0, 43, 91); text-decoration: none;" href="http://www.meng-jiang.com/"><font size="4"><b><p><img src="image/MengJiang.jpeg" alt="Smiley face" align="left" height="90" width="80"></p> &nbsp;Meng Jiang </b></font></a></div>  is an Assistant Professor in the Department of Computer Science and Engineering at the University of Notre Dame. His research interests include data mining, machine learning, and information extraction. His research work focuses on graph learning and knowledge graph. He has delivered seven tutorials in conferences such as KDD, SIGMOD, WWW, CIKM, and ICDM on user modeling, graph learning, and knowledge graph.
<p></p>	




 <hr>

<!-- <h2 id="presenter">References</h2> -->

<!-- <h2 id="proposal">Proposal Reference</h2>
<p><a style="color: rgb(0, 43, 91); text-decoration: none;" href="KDD20_Tutorial.pdf">Multi-modal Network Representation Learning<font color="red"></font> </a>
<br>Chuxu Zhang, Meng Jiang, Xiangliang Zhang, Yanfang Ye, Nitesh V. Chawla
<br>Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2020
</p>
</ul>

 <hr> -->

<div style="text-align:center"><font size="2">Last update in 5/2021</font></a></div>



</td>
</tr>
</table>
</body>
</div>

</html>
